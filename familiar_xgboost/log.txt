2023-03-02 15:49:25	MESSAGE	Setup report: Validation is internal only.
2023-03-02 15:49:25	MESSAGE	Setup report: Feature selection and model building on 1 repetitions of 10-fold cross validation of the training data.
2023-03-02 15:49:26	MESSAGE	Creating iterations: Starting creation of iterations.
2023-03-02 15:49:36	MESSAGE	Creating iterations: Finished creation of iterations.
2023-03-02 15:49:36	MESSAGE	Creating iterations: New project id is: '20230302154936'.
2023-03-02 15:49:46	MESSAGE	
Pre-processing: Starting preprocessing for run 1 of 10.
2023-03-02 15:49:46	MESSAGE	  Pre-processing: 171 samples were initially available.
2023-03-02 15:49:46	MESSAGE	  Pre-processing: 0 samples were removed because of missing outcome data. 171 samples remain.
2023-03-02 15:49:46	MESSAGE	  Pre-processing: 13 features were initially available.
2023-03-02 15:49:46	MESSAGE	  Pre-processing: 0 features were removed because of a high fraction of missing values. 13 features remain.
2023-03-02 15:49:46	MESSAGE	  Pre-processing: 11 samples were removed because of missing feature data. 160 samples remain.
2023-03-02 15:49:47	MESSAGE	  Pre-processing: 0 features were removed due to invariance. 13 features remain.
2023-03-02 15:49:47	MESSAGE	  Pre-processing: Adding value distribution statistics to features.
2023-03-02 15:49:47	MESSAGE	  Pre-processing: Performing transformations to normalise feature value distributions.
2023-03-02 15:49:48	MESSAGE	  Pre-processing: Feature distributions have been transformed for normalisation.
2023-03-02 15:49:48	MESSAGE	  Pre-processing: Extracting normalisation parameters from feature data.
2023-03-02 15:49:54	MESSAGE	  Pre-processing: Feature data were normalised.
2023-03-02 15:49:54	MESSAGE	  Pre-processing: Adding imputation information to features.
2023-03-02 15:49:55	MESSAGE	  Pre-processing: Starting clustering of redundant features
2023-03-02 15:49:55	MESSAGE	    Computing similarity between 13 features using the mutual_information metric for clustering using the hclust method.
2023-03-02 15:49:55	MESSAGE	    14 feature clusteres were created from 14 features. 0 clusters contain more than one feature. The remaining 14 clusters are singular.
2023-03-02 15:49:55	MESSAGE	
Pre-processing: Starting preprocessing for run 2 of 10.
2023-03-02 15:49:56	MESSAGE	  Pre-processing: 170 samples were initially available.
2023-03-02 15:49:56	MESSAGE	  Pre-processing: 0 samples were removed because of missing outcome data. 170 samples remain.
2023-03-02 15:49:56	MESSAGE	  Pre-processing: 13 features were initially available.
2023-03-02 15:49:56	MESSAGE	  Pre-processing: 0 features were removed because of a high fraction of missing values. 13 features remain.
2023-03-02 15:49:56	MESSAGE	  Pre-processing: 12 samples were removed because of missing feature data. 158 samples remain.
2023-03-02 15:49:56	MESSAGE	  Pre-processing: 0 features were removed due to invariance. 13 features remain.
2023-03-02 15:49:56	MESSAGE	  Pre-processing: Adding value distribution statistics to features.
2023-03-02 15:49:56	MESSAGE	  Pre-processing: Performing transformations to normalise feature value distributions.
2023-03-02 15:49:57	MESSAGE	  Pre-processing: Feature distributions have been transformed for normalisation.
2023-03-02 15:49:57	MESSAGE	  Pre-processing: Extracting normalisation parameters from feature data.
2023-03-02 15:50:04	MESSAGE	  Pre-processing: Feature data were normalised.
2023-03-02 15:50:04	MESSAGE	  Pre-processing: Adding imputation information to features.
2023-03-02 15:50:05	MESSAGE	  Pre-processing: Starting clustering of redundant features
2023-03-02 15:50:05	MESSAGE	    Computing similarity between 13 features using the mutual_information metric for clustering using the hclust method.
2023-03-02 15:50:06	MESSAGE	    14 feature clusteres were created from 14 features. 0 clusters contain more than one feature. The remaining 14 clusters are singular.
2023-03-02 15:50:06	MESSAGE	
Pre-processing: Starting preprocessing for run 3 of 10.
2023-03-02 15:50:06	MESSAGE	  Pre-processing: 171 samples were initially available.
2023-03-02 15:50:06	MESSAGE	  Pre-processing: 0 samples were removed because of missing outcome data. 171 samples remain.
2023-03-02 15:50:06	MESSAGE	  Pre-processing: 13 features were initially available.
2023-03-02 15:50:06	MESSAGE	  Pre-processing: 0 features were removed because of a high fraction of missing values. 13 features remain.
2023-03-02 15:50:06	MESSAGE	  Pre-processing: 12 samples were removed because of missing feature data. 159 samples remain.
2023-03-02 15:50:06	MESSAGE	  Pre-processing: 0 features were removed due to invariance. 13 features remain.
2023-03-02 15:50:06	MESSAGE	  Pre-processing: Adding value distribution statistics to features.
2023-03-02 15:50:06	MESSAGE	  Pre-processing: Performing transformations to normalise feature value distributions.
2023-03-02 15:50:13	MESSAGE	  Pre-processing: Feature distributions have been transformed for normalisation.
2023-03-02 15:50:13	MESSAGE	  Pre-processing: Extracting normalisation parameters from feature data.
2023-03-02 15:50:13	MESSAGE	  Pre-processing: Feature data were normalised.
2023-03-02 15:50:13	MESSAGE	  Pre-processing: Adding imputation information to features.
2023-03-02 15:50:14	MESSAGE	  Pre-processing: Starting clustering of redundant features
2023-03-02 15:50:14	MESSAGE	    Computing similarity between 13 features using the mutual_information metric for clustering using the hclust method.
2023-03-02 15:50:14	MESSAGE	    14 feature clusteres were created from 14 features. 0 clusters contain more than one feature. The remaining 14 clusters are singular.
2023-03-02 15:50:14	MESSAGE	
Pre-processing: Starting preprocessing for run 4 of 10.
2023-03-02 15:50:15	MESSAGE	  Pre-processing: 168 samples were initially available.
2023-03-02 15:50:15	MESSAGE	  Pre-processing: 0 samples were removed because of missing outcome data. 168 samples remain.
2023-03-02 15:50:15	MESSAGE	  Pre-processing: 13 features were initially available.
2023-03-02 15:50:15	MESSAGE	  Pre-processing: 0 features were removed because of a high fraction of missing values. 13 features remain.
2023-03-02 15:50:15	MESSAGE	  Pre-processing: 7 samples were removed because of missing feature data. 161 samples remain.
2023-03-02 15:50:15	MESSAGE	  Pre-processing: 0 features were removed due to invariance. 13 features remain.
2023-03-02 15:50:15	MESSAGE	  Pre-processing: Adding value distribution statistics to features.
2023-03-02 15:50:15	MESSAGE	  Pre-processing: Performing transformations to normalise feature value distributions.
2023-03-02 15:50:22	MESSAGE	  Pre-processing: Feature distributions have been transformed for normalisation.
2023-03-02 15:50:22	MESSAGE	  Pre-processing: Extracting normalisation parameters from feature data.
2023-03-02 15:50:22	MESSAGE	  Pre-processing: Feature data were normalised.
2023-03-02 15:50:23	MESSAGE	  Pre-processing: Adding imputation information to features.
2023-03-02 15:50:23	MESSAGE	  Pre-processing: Starting clustering of redundant features
2023-03-02 15:50:24	MESSAGE	    Computing similarity between 13 features using the mutual_information metric for clustering using the hclust method.
2023-03-02 15:50:24	MESSAGE	    14 feature clusteres were created from 14 features. 0 clusters contain more than one feature. The remaining 14 clusters are singular.
2023-03-02 15:50:24	MESSAGE	
Pre-processing: Starting preprocessing for run 5 of 10.
2023-03-02 15:50:24	MESSAGE	  Pre-processing: 171 samples were initially available.
2023-03-02 15:50:25	MESSAGE	  Pre-processing: 0 samples were removed because of missing outcome data. 171 samples remain.
2023-03-02 15:50:25	MESSAGE	  Pre-processing: 13 features were initially available.
2023-03-02 15:50:25	MESSAGE	  Pre-processing: 0 features were removed because of a high fraction of missing values. 13 features remain.
2023-03-02 15:50:25	MESSAGE	  Pre-processing: 10 samples were removed because of missing feature data. 161 samples remain.
2023-03-02 15:50:25	MESSAGE	  Pre-processing: 0 features were removed due to invariance. 13 features remain.
2023-03-02 15:50:25	MESSAGE	  Pre-processing: Adding value distribution statistics to features.
2023-03-02 15:50:25	MESSAGE	  Pre-processing: Performing transformations to normalise feature value distributions.
2023-03-02 15:50:32	MESSAGE	  Pre-processing: Feature distributions have been transformed for normalisation.
2023-03-02 15:50:32	MESSAGE	  Pre-processing: Extracting normalisation parameters from feature data.
2023-03-02 15:50:32	MESSAGE	  Pre-processing: Feature data were normalised.
2023-03-02 15:50:33	MESSAGE	  Pre-processing: Adding imputation information to features.
2023-03-02 15:50:33	MESSAGE	  Pre-processing: Starting clustering of redundant features
2023-03-02 15:50:34	MESSAGE	    Computing similarity between 13 features using the mutual_information metric for clustering using the hclust method.
2023-03-02 15:50:34	MESSAGE	    14 feature clusteres were created from 14 features. 0 clusters contain more than one feature. The remaining 14 clusters are singular.
2023-03-02 15:50:34	MESSAGE	
Pre-processing: Starting preprocessing for run 6 of 10.
2023-03-02 15:50:34	MESSAGE	  Pre-processing: 170 samples were initially available.
2023-03-02 15:50:34	MESSAGE	  Pre-processing: 0 samples were removed because of missing outcome data. 170 samples remain.
2023-03-02 15:50:34	MESSAGE	  Pre-processing: 13 features were initially available.
2023-03-02 15:50:34	MESSAGE	  Pre-processing: 0 features were removed because of a high fraction of missing values. 13 features remain.
2023-03-02 15:50:35	MESSAGE	  Pre-processing: 11 samples were removed because of missing feature data. 159 samples remain.
2023-03-02 15:50:35	MESSAGE	  Pre-processing: 0 features were removed due to invariance. 13 features remain.
2023-03-02 15:50:35	MESSAGE	  Pre-processing: Adding value distribution statistics to features.
2023-03-02 15:50:35	MESSAGE	  Pre-processing: Performing transformations to normalise feature value distributions.
2023-03-02 15:50:36	MESSAGE	  Pre-processing: Feature distributions have been transformed for normalisation.
2023-03-02 15:50:36	MESSAGE	  Pre-processing: Extracting normalisation parameters from feature data.
2023-03-02 15:50:36	MESSAGE	  Pre-processing: Feature data were normalised.
2023-03-02 15:50:36	MESSAGE	  Pre-processing: Adding imputation information to features.
2023-03-02 15:50:37	MESSAGE	  Pre-processing: Starting clustering of redundant features
2023-03-02 15:50:37	MESSAGE	    Computing similarity between 13 features using the mutual_information metric for clustering using the hclust method.
2023-03-02 15:50:37	MESSAGE	    14 feature clusteres were created from 14 features. 0 clusters contain more than one feature. The remaining 14 clusters are singular.
2023-03-02 15:50:37	MESSAGE	
Pre-processing: Starting preprocessing for run 7 of 10.
2023-03-02 15:50:38	MESSAGE	  Pre-processing: 171 samples were initially available.
2023-03-02 15:50:38	MESSAGE	  Pre-processing: 0 samples were removed because of missing outcome data. 171 samples remain.
2023-03-02 15:50:38	MESSAGE	  Pre-processing: 13 features were initially available.
2023-03-02 15:50:38	MESSAGE	  Pre-processing: 0 features were removed because of a high fraction of missing values. 13 features remain.
2023-03-02 15:50:38	MESSAGE	  Pre-processing: 12 samples were removed because of missing feature data. 159 samples remain.
2023-03-02 15:50:38	MESSAGE	  Pre-processing: 0 features were removed due to invariance. 13 features remain.
2023-03-02 15:50:38	MESSAGE	  Pre-processing: Adding value distribution statistics to features.
2023-03-02 15:50:38	MESSAGE	  Pre-processing: Performing transformations to normalise feature value distributions.
2023-03-02 15:50:39	MESSAGE	  Pre-processing: Feature distributions have been transformed for normalisation.
2023-03-02 15:50:39	MESSAGE	  Pre-processing: Extracting normalisation parameters from feature data.
2023-03-02 15:50:40	MESSAGE	  Pre-processing: Feature data were normalised.
2023-03-02 15:50:41	MESSAGE	  Pre-processing: Adding imputation information to features.
2023-03-02 15:50:41	MESSAGE	  Pre-processing: Starting clustering of redundant features
2023-03-02 15:50:41	MESSAGE	    Computing similarity between 13 features using the mutual_information metric for clustering using the hclust method.
2023-03-02 15:50:42	MESSAGE	    14 feature clusteres were created from 14 features. 0 clusters contain more than one feature. The remaining 14 clusters are singular.
2023-03-02 15:50:42	MESSAGE	
Pre-processing: Starting preprocessing for run 8 of 10.
2023-03-02 15:50:42	MESSAGE	  Pre-processing: 170 samples were initially available.
2023-03-02 15:50:42	MESSAGE	  Pre-processing: 0 samples were removed because of missing outcome data. 170 samples remain.
2023-03-02 15:50:42	MESSAGE	  Pre-processing: 13 features were initially available.
2023-03-02 15:50:42	MESSAGE	  Pre-processing: 0 features were removed because of a high fraction of missing values. 13 features remain.
2023-03-02 15:50:42	MESSAGE	  Pre-processing: 11 samples were removed because of missing feature data. 159 samples remain.
2023-03-02 15:50:42	MESSAGE	  Pre-processing: 0 features were removed due to invariance. 13 features remain.
2023-03-02 15:50:42	MESSAGE	  Pre-processing: Adding value distribution statistics to features.
2023-03-02 15:50:42	MESSAGE	  Pre-processing: Performing transformations to normalise feature value distributions.
2023-03-02 15:50:43	MESSAGE	  Pre-processing: Feature distributions have been transformed for normalisation.
2023-03-02 15:50:43	MESSAGE	  Pre-processing: Extracting normalisation parameters from feature data.
2023-03-02 15:50:43	MESSAGE	  Pre-processing: Feature data were normalised.
2023-03-02 15:50:44	MESSAGE	  Pre-processing: Adding imputation information to features.
2023-03-02 15:50:44	MESSAGE	  Pre-processing: Starting clustering of redundant features
2023-03-02 15:50:44	MESSAGE	    Computing similarity between 13 features using the mutual_information metric for clustering using the hclust method.
2023-03-02 15:50:45	MESSAGE	    14 feature clusteres were created from 14 features. 0 clusters contain more than one feature. The remaining 14 clusters are singular.
2023-03-02 15:50:45	MESSAGE	
Pre-processing: Starting preprocessing for run 9 of 10.
2023-03-02 15:50:45	MESSAGE	  Pre-processing: 173 samples were initially available.
2023-03-02 15:50:45	MESSAGE	  Pre-processing: 0 samples were removed because of missing outcome data. 173 samples remain.
2023-03-02 15:50:45	MESSAGE	  Pre-processing: 13 features were initially available.
2023-03-02 15:50:45	MESSAGE	  Pre-processing: 0 features were removed because of a high fraction of missing values. 13 features remain.
2023-03-02 15:50:45	MESSAGE	  Pre-processing: 11 samples were removed because of missing feature data. 162 samples remain.
2023-03-02 15:50:45	MESSAGE	  Pre-processing: 0 features were removed due to invariance. 13 features remain.
2023-03-02 15:50:45	MESSAGE	  Pre-processing: Adding value distribution statistics to features.
2023-03-02 15:50:45	MESSAGE	  Pre-processing: Performing transformations to normalise feature value distributions.
2023-03-02 15:50:46	MESSAGE	  Pre-processing: Feature distributions have been transformed for normalisation.
2023-03-02 15:50:46	MESSAGE	  Pre-processing: Extracting normalisation parameters from feature data.
2023-03-02 15:50:46	MESSAGE	  Pre-processing: Feature data were normalised.
2023-03-02 15:50:47	MESSAGE	  Pre-processing: Adding imputation information to features.
2023-03-02 15:50:47	MESSAGE	  Pre-processing: Starting clustering of redundant features
2023-03-02 15:50:48	MESSAGE	    Computing similarity between 13 features using the mutual_information metric for clustering using the hclust method.
2023-03-02 15:50:48	MESSAGE	    14 feature clusteres were created from 14 features. 0 clusters contain more than one feature. The remaining 14 clusters are singular.
2023-03-02 15:50:48	MESSAGE	
Pre-processing: Starting preprocessing for run 10 of 10.
2023-03-02 15:50:48	MESSAGE	  Pre-processing: 175 samples were initially available.
2023-03-02 15:50:48	MESSAGE	  Pre-processing: 0 samples were removed because of missing outcome data. 175 samples remain.
2023-03-02 15:50:48	MESSAGE	  Pre-processing: 13 features were initially available.
2023-03-02 15:50:48	MESSAGE	  Pre-processing: 0 features were removed because of a high fraction of missing values. 13 features remain.
2023-03-02 15:50:48	MESSAGE	  Pre-processing: 11 samples were removed because of missing feature data. 164 samples remain.
2023-03-02 15:50:49	MESSAGE	  Pre-processing: 0 features were removed due to invariance. 13 features remain.
2023-03-02 15:50:49	MESSAGE	  Pre-processing: Adding value distribution statistics to features.
2023-03-02 15:50:49	MESSAGE	  Pre-processing: Performing transformations to normalise feature value distributions.
2023-03-02 15:50:49	MESSAGE	  Pre-processing: Feature distributions have been transformed for normalisation.
2023-03-02 15:50:49	MESSAGE	  Pre-processing: Extracting normalisation parameters from feature data.
2023-03-02 15:50:50	MESSAGE	  Pre-processing: Feature data were normalised.
2023-03-02 15:50:50	MESSAGE	  Pre-processing: Adding imputation information to features.
2023-03-02 15:50:51	MESSAGE	  Pre-processing: Starting clustering of redundant features
2023-03-02 15:50:51	MESSAGE	    Computing similarity between 13 features using the mutual_information metric for clustering using the hclust method.
2023-03-02 15:50:51	MESSAGE	    14 feature clusteres were created from 14 features. 0 clusters contain more than one feature. The remaining 14 clusters are singular.
2023-03-02 15:50:51	MESSAGE	
Feature selection: starting feature selection using "mrmr" method.
2023-03-02 15:50:52	MESSAGE	  Hyperparameter optimisation: Starting parameter optimisation for the mrmr variable importance method.
2023-03-02 15:50:58	MESSAGE	
2023-03-02 15:50:58	MESSAGE	  Hyperparameter optimisation: Completed parameter optimisation for the mrmr variable importance method.
2023-03-02 15:51:03	MESSAGE	Feature selection: feature selection using "mrmr" method has been completed.
2023-03-02 15:51:03	MESSAGE	
Model building: starting model building using "xgboost_tree" learner, based on "mrmr" feature selection.
2023-03-02 15:51:04	MESSAGE	  Hyperparameter optimisation: Starting parameter optimisation for the xgboost_tree learner, based on variable importances from the mrmr variable importance method.
2023-03-02 15:51:04	MESSAGE	
2023-03-02 15:51:04	MESSAGE	    Starting hyperparameter optimisation for data subsample 1 of 10.
2023-03-02 15:51:04	MESSAGE	      Hyperparameter optimisation is conducted using the auc_roc metric by maximising out-of-bag performance.
2023-03-02 15:51:04	MESSAGE	      Candidate hyperparameter sets after the initial run are selected after inferring utility using a localised approximate Gaussian Process.
2023-03-02 15:51:04	MESSAGE	      Utility is measured as expected improvement.
2023-03-02 15:51:10	MESSAGE	      Computing variable importance for 20 bootstraps.
2023-03-02 15:51:15	MESSAGE	      Compute initial model performance based on 100 hyperparameter sets.
2023-03-02 15:52:21	MESSAGE	      Hyperparameter optimisation: Initialisation complete: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; sign_size: 2; n_boost: 3; learning_rate: -2; lambda: -3; alpha: -1; tree_depth: 3; sample_size: 1; min_child_weight: 1; gamma: -6
2023-03-02 15:53:03	MESSAGE	      Intensify step 1 using 20 challenger hyperparameter sets.
2023-03-02 15:53:12	MESSAGE	      Hyperparameter optimisation: SMBO iteration 1: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; sign_size: 2; n_boost: 3; learning_rate: -2; lambda: -3; alpha: -1; tree_depth: 3; sample_size: 1; min_child_weight: 1; gamma: -6
2023-03-02 15:53:16	MESSAGE	      Intensify step 1 using 4 challenger hyperparameter sets.
2023-03-02 15:53:20	MESSAGE	      Hyperparameter optimisation: SMBO iteration 2: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; sign_size: 2; n_boost: 3; learning_rate: -2; lambda: -3; alpha: -1; tree_depth: 3; sample_size: 1; min_child_weight: 1; gamma: -6
2023-03-02 15:53:24	MESSAGE	      Intensify step 1 using 4 challenger hyperparameter sets.
2023-03-02 15:53:29	MESSAGE	      Hyperparameter optimisation: SMBO iteration 3: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; sign_size: 2; n_boost: 3; learning_rate: -2; lambda: -3; alpha: -1; tree_depth: 3; sample_size: 1; min_child_weight: 1; gamma: -6
2023-03-02 15:53:29	MESSAGE	    Hyperparameter optimisation: Optimisation stopped early as convergence was achieved.
2023-03-02 15:53:29	MESSAGE	    Hyperparameter optimisation: A suitable set of hyperparameters was identified: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; sign_size: 2; n_boost: 3; learning_rate: -2; lambda: -3; alpha: -1; tree_depth: 3; sample_size: 1; min_child_weight: 1; gamma: -6
2023-03-02 15:53:30	MESSAGE	
2023-03-02 15:53:30	MESSAGE	    Starting hyperparameter optimisation for data subsample 2 of 10.
2023-03-02 15:53:30	MESSAGE	      Hyperparameter optimisation is conducted using the auc_roc metric by maximising out-of-bag performance.
2023-03-02 15:53:30	MESSAGE	      Candidate hyperparameter sets after the initial run are selected after inferring utility using a localised approximate Gaussian Process.
2023-03-02 15:53:30	MESSAGE	      Utility is measured as expected improvement.
2023-03-02 15:53:38	MESSAGE	      Computing variable importance for 20 bootstraps.
2023-03-02 15:53:42	MESSAGE	      Compute initial model performance based on 100 hyperparameter sets.
2023-03-02 15:54:53	MESSAGE	      Hyperparameter optimisation: Initialisation complete: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; sign_size: 1; n_boost: 3; learning_rate: -1; lambda: -1; alpha: -1; tree_depth: 1; sample_size: 1; min_child_weight: 0; gamma: -6
2023-03-02 15:55:36	MESSAGE	      Intensify step 1 using 20 challenger hyperparameter sets.
2023-03-02 15:55:54	MESSAGE	      Hyperparameter optimisation: SMBO iteration 1: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; sign_size: 1; n_boost: 3; learning_rate: -1; lambda: -1; alpha: -1; tree_depth: 1; sample_size: 1; min_child_weight: 0; gamma: -6
2023-03-02 15:57:04	MESSAGE	      Intensify step 1 using 4 challenger hyperparameter sets.
2023-03-02 15:57:10	MESSAGE	      Hyperparameter optimisation: SMBO iteration 2: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; sign_size: 1; n_boost: 3; learning_rate: -1; lambda: -1; alpha: -1; tree_depth: 1; sample_size: 1; min_child_weight: 0; gamma: -6
2023-03-02 15:57:15	MESSAGE	      Intensify step 1 using 4 challenger hyperparameter sets.
2023-03-02 15:57:20	MESSAGE	      Hyperparameter optimisation: SMBO iteration 3: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; sign_size: 1; n_boost: 3; learning_rate: -1; lambda: -1; alpha: -1; tree_depth: 1; sample_size: 1; min_child_weight: 0; gamma: -6
2023-03-02 15:57:20	MESSAGE	    Hyperparameter optimisation: Optimisation stopped early as convergence was achieved.
2023-03-02 15:57:20	MESSAGE	    Hyperparameter optimisation: A suitable set of hyperparameters was identified: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; sign_size: 1; n_boost: 3; learning_rate: -1; lambda: -1; alpha: -1; tree_depth: 1; sample_size: 1; min_child_weight: 0; gamma: -6
2023-03-02 15:57:21	MESSAGE	
2023-03-02 15:57:21	MESSAGE	    Starting hyperparameter optimisation for data subsample 3 of 10.
2023-03-02 15:57:21	MESSAGE	      Hyperparameter optimisation is conducted using the auc_roc metric by maximising out-of-bag performance.
2023-03-02 15:57:21	MESSAGE	      Candidate hyperparameter sets after the initial run are selected after inferring utility using a localised approximate Gaussian Process.
2023-03-02 15:57:21	MESSAGE	      Utility is measured as expected improvement.
2023-03-02 15:57:30	MESSAGE	      Computing variable importance for 20 bootstraps.
2023-03-02 15:57:35	MESSAGE	      Compute initial model performance based on 100 hyperparameter sets.
2023-03-02 15:58:46	MESSAGE	      Hyperparameter optimisation: Initialisation complete: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; sign_size: 2; n_boost: 2; learning_rate: -3; lambda: 3; alpha: -6; tree_depth: 2; sample_size: 0.5; min_child_weight: 1; gamma: -6
2023-03-02 15:59:23	MESSAGE	      Intensify step 1 using 20 challenger hyperparameter sets.
2023-03-02 15:59:31	MESSAGE	      Hyperparameter optimisation: SMBO iteration 1: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; sign_size: 2; n_boost: 2; learning_rate: -3; lambda: 3; alpha: -6; tree_depth: 2; sample_size: 0.5; min_child_weight: 1; gamma: -6
2023-03-02 16:00:32	MESSAGE	      Intensify step 1 using 20 challenger hyperparameter sets.
2023-03-02 16:00:55	MESSAGE	      Hyperparameter optimisation: SMBO iteration 2: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; sign_size: 2; n_boost: 2; learning_rate: -3; lambda: 3; alpha: -6; tree_depth: 2; sample_size: 0.5; min_child_weight: 1; gamma: -6
2023-03-02 16:00:59	MESSAGE	      Intensify step 1 using 4 challenger hyperparameter sets.
2023-03-02 16:01:03	MESSAGE	      Hyperparameter optimisation: SMBO iteration 3: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; sign_size: 2; n_boost: 2; learning_rate: -3; lambda: 3; alpha: -6; tree_depth: 2; sample_size: 0.5; min_child_weight: 1; gamma: -6
2023-03-02 16:01:03	MESSAGE	    Hyperparameter optimisation: Optimisation stopped early as convergence was achieved.
2023-03-02 16:01:03	MESSAGE	    Hyperparameter optimisation: A suitable set of hyperparameters was identified: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; sign_size: 2; n_boost: 2; learning_rate: -3; lambda: 3; alpha: -6; tree_depth: 2; sample_size: 0.5; min_child_weight: 1; gamma: -6
2023-03-02 16:01:04	MESSAGE	
2023-03-02 16:01:04	MESSAGE	    Starting hyperparameter optimisation for data subsample 4 of 10.
2023-03-02 16:01:04	MESSAGE	      Hyperparameter optimisation is conducted using the auc_roc metric by maximising out-of-bag performance.
2023-03-02 16:01:04	MESSAGE	      Candidate hyperparameter sets after the initial run are selected after inferring utility using a localised approximate Gaussian Process.
2023-03-02 16:01:04	MESSAGE	      Utility is measured as expected improvement.
2023-03-02 16:01:21	MESSAGE	      Computing variable importance for 20 bootstraps.
2023-03-02 16:01:43	MESSAGE	      Compute initial model performance based on 100 hyperparameter sets.
2023-03-02 16:06:23	MESSAGE	      Hyperparameter optimisation: Initialisation complete: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; sign_size: 1; n_boost: 3; learning_rate: -1; lambda: -6; alpha: -1; tree_depth: 7; sample_size: 0.3; min_child_weight: 0; gamma: -6
2023-03-02 16:08:57	MESSAGE	      Intensify step 1 using 20 challenger hyperparameter sets.
2023-03-02 16:10:23	MESSAGE	      Hyperparameter optimisation: SMBO iteration 1: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; sign_size: 1; n_boost: 3; learning_rate: -1; lambda: -6; alpha: -1; tree_depth: 7; sample_size: 0.3; min_child_weight: 0; gamma: -6
2023-03-02 16:13:59	MESSAGE	      Intensify step 1 using 20 challenger hyperparameter sets.
2023-03-02 16:14:50	MESSAGE	      Hyperparameter optimisation: SMBO iteration 2: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; sign_size: 1; n_boost: 3; learning_rate: -1; lambda: -6; alpha: -1; tree_depth: 7; sample_size: 0.3; min_child_weight: 0; gamma: -6
2023-03-02 16:15:05	MESSAGE	      Intensify step 1 using 4 challenger hyperparameter sets.
2023-03-02 16:15:40	MESSAGE	      Hyperparameter optimisation: SMBO iteration 3: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; sign_size: 1; n_boost: 3; learning_rate: -1; lambda: -6; alpha: -1; tree_depth: 7; sample_size: 0.3; min_child_weight: 0; gamma: -6
2023-03-02 16:15:40	MESSAGE	    Hyperparameter optimisation: Optimisation stopped early as convergence was achieved.
2023-03-02 16:15:41	MESSAGE	    Hyperparameter optimisation: A suitable set of hyperparameters was identified: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; sign_size: 1; n_boost: 3; learning_rate: -1; lambda: -6; alpha: -1; tree_depth: 7; sample_size: 0.3; min_child_weight: 0; gamma: -6
2023-03-02 16:15:44	MESSAGE	
2023-03-02 16:15:44	MESSAGE	    Starting hyperparameter optimisation for data subsample 5 of 10.
2023-03-02 16:15:44	MESSAGE	      Hyperparameter optimisation is conducted using the auc_roc metric by maximising out-of-bag performance.
2023-03-02 16:15:44	MESSAGE	      Candidate hyperparameter sets after the initial run are selected after inferring utility using a localised approximate Gaussian Process.
2023-03-02 16:15:44	MESSAGE	      Utility is measured as expected improvement.
2023-03-02 16:16:14	MESSAGE	      Computing variable importance for 20 bootstraps.
2023-03-02 16:16:34	MESSAGE	      Compute initial model performance based on 100 hyperparameter sets.
2023-03-02 16:22:31	MESSAGE	      Hyperparameter optimisation: Initialisation complete: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; n_boost: 3; learning_rate: -1; lambda: -6; alpha: 1; tree_depth: 2; sample_size: 0.5; min_child_weight: 1; gamma: -1
2023-03-02 16:25:03	MESSAGE	      Intensify step 1 using 20 challenger hyperparameter sets.
2023-03-02 16:26:25	MESSAGE	      Hyperparameter optimisation: SMBO iteration 1: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; n_boost: 3; learning_rate: -1; lambda: -6; alpha: 1; tree_depth: 2; sample_size: 0.5; min_child_weight: 1; gamma: -1
2023-03-02 16:26:39	MESSAGE	      Intensify step 1 using 4 challenger hyperparameter sets.
2023-03-02 16:27:26	MESSAGE	      Hyperparameter optimisation: SMBO iteration 2: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; n_boost: 3; learning_rate: -1; lambda: -6; alpha: 1; tree_depth: 2; sample_size: 0.5; min_child_weight: 1; gamma: -1
2023-03-02 16:27:43	MESSAGE	      Intensify step 1 using 4 challenger hyperparameter sets.
2023-03-02 16:28:39	MESSAGE	      Hyperparameter optimisation: SMBO iteration 3: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; n_boost: 3; learning_rate: -1; lambda: -6; alpha: 1; tree_depth: 2; sample_size: 0.5; min_child_weight: 1; gamma: -1
2023-03-02 16:28:39	MESSAGE	    Hyperparameter optimisation: Optimisation stopped early as convergence was achieved.
2023-03-02 16:28:40	MESSAGE	    Hyperparameter optimisation: A suitable set of hyperparameters was identified: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; n_boost: 3; learning_rate: -1; lambda: -6; alpha: 1; tree_depth: 2; sample_size: 0.5; min_child_weight: 1; gamma: -1
2023-03-02 16:28:44	MESSAGE	
2023-03-02 16:28:44	MESSAGE	    Starting hyperparameter optimisation for data subsample 6 of 10.
2023-03-02 16:28:44	MESSAGE	      Hyperparameter optimisation is conducted using the auc_roc metric by maximising out-of-bag performance.
2023-03-02 16:28:45	MESSAGE	      Candidate hyperparameter sets after the initial run are selected after inferring utility using a localised approximate Gaussian Process.
2023-03-02 16:28:45	MESSAGE	      Utility is measured as expected improvement.
2023-03-02 16:29:18	MESSAGE	      Computing variable importance for 20 bootstraps.
2023-03-02 16:29:46	MESSAGE	      Compute initial model performance based on 100 hyperparameter sets.
2023-03-02 16:35:21	MESSAGE	      Hyperparameter optimisation: Initialisation complete: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; n_boost: 2; learning_rate: -1; lambda: -6; alpha: -6; tree_depth: 1; sample_size: 0.3; min_child_weight: 1; gamma: 1
2023-03-02 16:37:11	MESSAGE	      Intensify step 1 using 20 challenger hyperparameter sets.
2023-03-02 16:38:01	MESSAGE	      Hyperparameter optimisation: SMBO iteration 1: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; n_boost: 2; learning_rate: -1; lambda: -6; alpha: -6; tree_depth: 1; sample_size: 0.3; min_child_weight: 1; gamma: 1
2023-03-02 16:41:32	MESSAGE	      Intensify step 1 using 20 challenger hyperparameter sets.
2023-03-02 16:42:10	MESSAGE	      Hyperparameter optimisation: SMBO iteration 2: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; n_boost: 2; learning_rate: -1; lambda: -6; alpha: -6; tree_depth: 1; sample_size: 0.3; min_child_weight: 1; gamma: 1
2023-03-02 16:42:26	MESSAGE	      Intensify step 1 using 4 challenger hyperparameter sets.
2023-03-02 16:42:40	MESSAGE	      Hyperparameter optimisation: SMBO iteration 3: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; n_boost: 2; learning_rate: -1; lambda: -6; alpha: -6; tree_depth: 1; sample_size: 0.3; min_child_weight: 1; gamma: 1
2023-03-02 16:42:41	MESSAGE	    Hyperparameter optimisation: Optimisation stopped early as convergence was achieved.
2023-03-02 16:42:42	MESSAGE	    Hyperparameter optimisation: A suitable set of hyperparameters was identified: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; n_boost: 2; learning_rate: -1; lambda: -6; alpha: -6; tree_depth: 1; sample_size: 0.3; min_child_weight: 1; gamma: 1
2023-03-02 16:42:45	MESSAGE	
2023-03-02 16:42:45	MESSAGE	    Starting hyperparameter optimisation for data subsample 7 of 10.
2023-03-02 16:42:45	MESSAGE	      Hyperparameter optimisation is conducted using the auc_roc metric by maximising out-of-bag performance.
2023-03-02 16:42:45	MESSAGE	      Candidate hyperparameter sets after the initial run are selected after inferring utility using a localised approximate Gaussian Process.
2023-03-02 16:42:45	MESSAGE	      Utility is measured as expected improvement.
2023-03-02 16:43:17	MESSAGE	      Computing variable importance for 20 bootstraps.
2023-03-02 16:43:38	MESSAGE	      Compute initial model performance based on 100 hyperparameter sets.
2023-03-02 16:48:56	MESSAGE	      Hyperparameter optimisation: Initialisation complete: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; n_boost: 0; learning_rate: -1; lambda: -1; alpha: 1; tree_depth: 2; sample_size: 1; min_child_weight: 1; gamma: 1
2023-03-02 16:51:23	MESSAGE	      Intensify step 1 using 20 challenger hyperparameter sets.
2023-03-02 16:52:06	MESSAGE	      Hyperparameter optimisation: SMBO iteration 1: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; n_boost: 0; learning_rate: -1; lambda: -1; alpha: 1; tree_depth: 2; sample_size: 1; min_child_weight: 1; gamma: 1
2023-03-02 16:53:45	MESSAGE	      Intensify step 1 using 20 challenger hyperparameter sets.
2023-03-02 16:53:53	MESSAGE	      Hyperparameter optimisation: SMBO iteration 2: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; n_boost: 0; learning_rate: -1; lambda: -1; alpha: 1; tree_depth: 2; sample_size: 1; min_child_weight: 1; gamma: 1
2023-03-02 16:53:57	MESSAGE	      Intensify step 1 using 4 challenger hyperparameter sets.
2023-03-02 16:53:59	MESSAGE	      Hyperparameter optimisation: SMBO iteration 3: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; n_boost: 0; learning_rate: -1; lambda: -1; alpha: 1; tree_depth: 2; sample_size: 1; min_child_weight: 1; gamma: 1
2023-03-02 16:53:59	MESSAGE	    Hyperparameter optimisation: Optimisation stopped early as convergence was achieved.
2023-03-02 16:53:59	MESSAGE	    Hyperparameter optimisation: A suitable set of hyperparameters was identified: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; n_boost: 0; learning_rate: -1; lambda: -1; alpha: 1; tree_depth: 2; sample_size: 1; min_child_weight: 1; gamma: 1
2023-03-02 16:54:01	MESSAGE	
2023-03-02 16:54:01	MESSAGE	    Starting hyperparameter optimisation for data subsample 8 of 10.
2023-03-02 16:54:01	MESSAGE	      Hyperparameter optimisation is conducted using the auc_roc metric by maximising out-of-bag performance.
2023-03-02 16:54:01	MESSAGE	      Candidate hyperparameter sets after the initial run are selected after inferring utility using a localised approximate Gaussian Process.
2023-03-02 16:54:01	MESSAGE	      Utility is measured as expected improvement.
2023-03-02 16:54:11	MESSAGE	      Computing variable importance for 20 bootstraps.
2023-03-02 16:54:15	MESSAGE	      Compute initial model performance based on 100 hyperparameter sets.
2023-03-02 16:55:11	MESSAGE	      Hyperparameter optimisation: Initialisation complete: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; sign_size: 2; n_boost: 3; learning_rate: -1; lambda: -6; alpha: -3; tree_depth: 1; sample_size: 0.5; min_child_weight: 0; gamma: -1
2023-03-02 16:55:45	MESSAGE	      Intensify step 1 using 20 challenger hyperparameter sets.
2023-03-02 16:56:02	MESSAGE	      Hyperparameter optimisation: SMBO iteration 1: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; sign_size: 2; n_boost: 3; learning_rate: -1; lambda: -6; alpha: -3; tree_depth: 1; sample_size: 0.5; min_child_weight: 0; gamma: -1
2023-03-02 16:57:00	MESSAGE	      Intensify step 1 using 20 challenger hyperparameter sets.
2023-03-02 16:57:10	MESSAGE	      Hyperparameter optimisation: SMBO iteration 2: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; sign_size: 2; n_boost: 3; learning_rate: -1; lambda: -6; alpha: -3; tree_depth: 1; sample_size: 0.5; min_child_weight: 0; gamma: -1
2023-03-02 16:57:15	MESSAGE	      Intensify step 1 using 4 challenger hyperparameter sets.
2023-03-02 16:57:22	MESSAGE	      Hyperparameter optimisation: SMBO iteration 3: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; sign_size: 2; n_boost: 3; learning_rate: -1; lambda: -6; alpha: -3; tree_depth: 1; sample_size: 0.5; min_child_weight: 0; gamma: -1
2023-03-02 16:57:22	MESSAGE	    Hyperparameter optimisation: Optimisation stopped early as convergence was achieved.
2023-03-02 16:57:22	MESSAGE	    Hyperparameter optimisation: A suitable set of hyperparameters was identified: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; sign_size: 2; n_boost: 3; learning_rate: -1; lambda: -6; alpha: -3; tree_depth: 1; sample_size: 0.5; min_child_weight: 0; gamma: -1
2023-03-02 16:57:23	MESSAGE	
2023-03-02 16:57:23	MESSAGE	    Starting hyperparameter optimisation for data subsample 9 of 10.
2023-03-02 16:57:24	MESSAGE	      Hyperparameter optimisation is conducted using the auc_roc metric by maximising out-of-bag performance.
2023-03-02 16:57:24	MESSAGE	      Candidate hyperparameter sets after the initial run are selected after inferring utility using a localised approximate Gaussian Process.
2023-03-02 16:57:24	MESSAGE	      Utility is measured as expected improvement.
2023-03-02 16:57:34	MESSAGE	      Computing variable importance for 20 bootstraps.
2023-03-02 16:57:39	MESSAGE	      Compute initial model performance based on 100 hyperparameter sets.
2023-03-02 16:58:34	MESSAGE	      Hyperparameter optimisation: Initialisation complete: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; n_boost: 2; learning_rate: -1; lambda: 1; alpha: -6; tree_depth: 3; sample_size: 0.3; min_child_weight: 1; gamma: -3
2023-03-02 16:59:21	MESSAGE	      Intensify step 1 using 20 challenger hyperparameter sets.
2023-03-02 16:59:37	MESSAGE	      Hyperparameter optimisation: SMBO iteration 1: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; n_boost: 2; learning_rate: -1; lambda: 1; alpha: -6; tree_depth: 3; sample_size: 0.3; min_child_weight: 1; gamma: -3
2023-03-02 16:59:41	MESSAGE	      Intensify step 1 using 4 challenger hyperparameter sets.
2023-03-02 16:59:45	MESSAGE	      Hyperparameter optimisation: SMBO iteration 2: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; n_boost: 2; learning_rate: -1; lambda: 1; alpha: -6; tree_depth: 3; sample_size: 0.3; min_child_weight: 1; gamma: -3
2023-03-02 16:59:49	MESSAGE	      Intensify step 1 using 4 challenger hyperparameter sets.
2023-03-02 16:59:57	MESSAGE	      Hyperparameter optimisation: SMBO iteration 3: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; n_boost: 2; learning_rate: -1; lambda: 1; alpha: -6; tree_depth: 3; sample_size: 0.3; min_child_weight: 1; gamma: -3
2023-03-02 16:59:57	MESSAGE	    Hyperparameter optimisation: Optimisation stopped early as convergence was achieved.
2023-03-02 16:59:57	MESSAGE	    Hyperparameter optimisation: A suitable set of hyperparameters was identified: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; n_boost: 2; learning_rate: -1; lambda: 1; alpha: -6; tree_depth: 3; sample_size: 0.3; min_child_weight: 1; gamma: -3
2023-03-02 16:59:58	MESSAGE	
2023-03-02 16:59:58	MESSAGE	    Starting hyperparameter optimisation for data subsample 10 of 10.
2023-03-02 16:59:58	MESSAGE	      Hyperparameter optimisation is conducted using the auc_roc metric by maximising out-of-bag performance.
2023-03-02 16:59:58	MESSAGE	      Candidate hyperparameter sets after the initial run are selected after inferring utility using a localised approximate Gaussian Process.
2023-03-02 16:59:58	MESSAGE	      Utility is measured as expected improvement.
2023-03-02 17:00:10	MESSAGE	      Computing variable importance for 20 bootstraps.
2023-03-02 17:00:14	MESSAGE	      Compute initial model performance based on 100 hyperparameter sets.
2023-03-02 17:01:24	MESSAGE	      Hyperparameter optimisation: Initialisation complete: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; n_boost: 2; learning_rate: -3; lambda: 1; alpha: -3; tree_depth: 3; sample_size: 0.3; min_child_weight: 1; gamma: -1
2023-03-02 17:02:09	MESSAGE	      Intensify step 1 using 20 challenger hyperparameter sets.
2023-03-02 17:02:17	MESSAGE	      Hyperparameter optimisation: SMBO iteration 1: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; n_boost: 2; learning_rate: -3; lambda: 1; alpha: -3; tree_depth: 3; sample_size: 0.3; min_child_weight: 1; gamma: -1
2023-03-02 17:02:21	MESSAGE	      Intensify step 1 using 4 challenger hyperparameter sets.
2023-03-02 17:02:29	MESSAGE	      Hyperparameter optimisation: SMBO iteration 2: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; n_boost: 2; learning_rate: -3; lambda: 1; alpha: -3; tree_depth: 3; sample_size: 0.3; min_child_weight: 1; gamma: -1
2023-03-02 17:02:33	MESSAGE	      Intensify step 1 using 4 challenger hyperparameter sets.
2023-03-02 17:02:41	MESSAGE	      Hyperparameter optimisation: SMBO iteration 3: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; n_boost: 2; learning_rate: -3; lambda: 1; alpha: -3; tree_depth: 3; sample_size: 0.3; min_child_weight: 1; gamma: -1
2023-03-02 17:02:41	MESSAGE	    Hyperparameter optimisation: Optimisation stopped early as convergence was achieved.
2023-03-02 17:02:42	MESSAGE	    Hyperparameter optimisation: A suitable set of hyperparameters was identified: summary score: 0.6667; validation optimisation score: 0.6667; auc_roc: 0.8333; n_boost: 2; learning_rate: -3; lambda: 1; alpha: -3; tree_depth: 3; sample_size: 0.3; min_child_weight: 1; gamma: -1
2023-03-02 17:02:42	MESSAGE	
2023-03-02 17:02:42	MESSAGE	  Hyperparameter optimisation: Completed parameter optimisation for the xgboost_tree learner, based on variable importances from the mrmr variable importance method.
2023-03-02 17:03:47	MESSAGE	Model building: model building using "xgboost_tree" learner, based on "mrmr" feature selection, has been completed.
2023-03-02 17:03:47	MESSAGE	
Evaluation: Creating ensemble models from individual models.
2023-03-02 17:03:52	MESSAGE	
Evaluation: Processing data to create familiarData objects.
2023-03-02 17:03:52	MESSAGE	  
Evaluation: Processing dataset 1 of 2.
2023-03-02 17:03:53	MESSAGE	    Computing pairwise similarity between features.
2023-03-02 17:03:53	MESSAGE	      Computing the point estimate of the value(s) of interest for the ensemble model as a whole. Computation is parallelised over bootstraps.
2023-03-02 17:03:53	MESSAGE	    Computing pairwise similarity between samples.
2023-03-02 17:03:54	MESSAGE	      Computing the point estimate of the value(s) of interest for the ensemble model as a whole. Computation is parallelised over bootstraps.
2023-03-02 17:05:09	MESSAGE	    Extracting variable importance obtained during feature selection.
2023-03-02 17:05:09	MESSAGE	    Extracting variable importance obtained from the models.
2023-03-02 17:05:09	MESSAGE	      Computing the point estimate of the value(s) of interest for the ensemble model from the 10 underlying models. 
2023-03-02 17:05:12	MESSAGE	    Computing permutation variable importance for models in the dataset.
2023-03-02 17:05:12	MESSAGE	      Computing the bias-corrected estimate with confidence interval of the value(s) of interest for the ensemble model from the 10 underlying models. 40 bootstrap samples are obtained for each model (total: 400). Computation is parallelised over models.
2023-03-02 17:06:32	MESSAGE	    Compute feature expression.
2023-03-02 17:06:32	MESSAGE	    Extracting univariate analysis information.
2023-03-02 17:06:33	MESSAGE	    Extracting hyperparameters from the models in the ensemble.
2023-03-02 17:06:33	MESSAGE	      Computing the point estimate of the value(s) of interest for the ensemble model from the 10 underlying models. 
2023-03-02 17:06:37	MESSAGE	    Computing ensemble predictions for the dataset.
2023-03-02 17:06:37	MESSAGE	      Computing the point estimate of the value(s) of interest for the ensemble model as a whole. Computation is parallelised over bootstraps.
2023-03-02 17:06:42	MESSAGE	    Computing model performance metrics on the dataset.
2023-03-02 17:06:42	MESSAGE	      Computing the bias-corrected estimate with confidence interval of the value(s) of interest for the ensemble model from the 10 underlying models. 40 bootstrap samples are obtained for each model (total: 400). Computation is parallelised over models.
2023-03-02 17:07:12	MESSAGE	    Computing data for decision curve analysis.
2023-03-02 17:07:12	MESSAGE	      Computing the bias-corrected estimate with confidence interval of the value(s) of interest for the ensemble model from the 10 underlying models. 40 bootstrap samples are obtained for each model (total: 400). Computation is parallelised over models.
2023-03-02 17:08:00	MESSAGE	    Assessing model calibration.
2023-03-02 17:08:00	MESSAGE	      Computing the bias-corrected estimate with confidence interval of the value(s) of interest for the ensemble model from the 10 underlying models. 40 bootstrap samples are obtained for each model (total: 400). Computation is parallelised over models.
2023-03-02 17:11:10	MESSAGE	    Computing receiver-operating characteristic curves.
2023-03-02 17:11:10	MESSAGE	      Computing the bias-corrected estimate with confidence interval of the value(s) of interest for the ensemble model from the 10 underlying models. 40 bootstrap samples are obtained for each model (total: 400). Computation is parallelised over models.
2023-03-02 17:12:41	MESSAGE	    Computing confusion matrix.
2023-03-02 17:12:41	MESSAGE	      Computing the point estimate of the value(s) of interest for the ensemble model as a whole. Computation is parallelised over bootstraps.
2023-03-02 17:12:45	MESSAGE	    Computing individual conditional expectation and partial dependence data for features in the dataset.
2023-03-02 17:12:45	MESSAGE	      Computing the point estimate of the value(s) of interest for the ensemble model as a whole. Computation is parallelised over bootstraps.
2023-03-02 17:12:45	MESSAGE	      Computing ICE / PD curves for "susp_tot".
2023-03-02 17:14:13	MESSAGE	  Evaluation: familiarData object 20230302154936_xgboost_tree_mrmr_1_1_pool_1_1_development_data was created.
2023-03-02 17:14:14	MESSAGE	  
Evaluation: Processing dataset 2 of 2.
2023-03-02 17:14:15	MESSAGE	    Computing pairwise similarity between features.
2023-03-02 17:14:15	MESSAGE	      Computing the point estimate of the value(s) of interest for the ensemble model as a whole. Computation is parallelised over bootstraps.
2023-03-02 17:14:15	MESSAGE	    Computing pairwise similarity between samples.
2023-03-02 17:14:15	MESSAGE	      Computing the point estimate of the value(s) of interest for the ensemble model as a whole. Computation is parallelised over bootstraps.
2023-03-02 17:15:21	MESSAGE	    Extracting variable importance obtained during feature selection.
2023-03-02 17:15:21	MESSAGE	    Extracting variable importance obtained from the models.
2023-03-02 17:15:21	MESSAGE	      Computing the point estimate of the value(s) of interest for the ensemble model from the 10 underlying models. 
2023-03-02 17:15:23	MESSAGE	    Computing permutation variable importance for models in the dataset.
2023-03-02 17:15:23	MESSAGE	      Computing the bias-corrected estimate with confidence interval of the value(s) of interest for the ensemble model from the 10 underlying models. 40 bootstrap samples are obtained for each model (total: 400). Computation is parallelised over models.
2023-03-02 17:16:31	MESSAGE	    Compute feature expression.
2023-03-02 17:16:31	MESSAGE	    Extracting univariate analysis information.
2023-03-02 17:16:32	MESSAGE	    Extracting hyperparameters from the models in the ensemble.
2023-03-02 17:16:32	MESSAGE	      Computing the point estimate of the value(s) of interest for the ensemble model from the 10 underlying models. 
2023-03-02 17:16:33	MESSAGE	    Computing ensemble predictions for the dataset.
2023-03-02 17:16:33	MESSAGE	      Computing the point estimate of the value(s) of interest for the ensemble model as a whole. Computation is parallelised over bootstraps.
2023-03-02 17:16:39	MESSAGE	    Computing model performance metrics on the dataset.
2023-03-02 17:16:39	MESSAGE	      Computing the bias-corrected estimate with confidence interval of the value(s) of interest for the ensemble model from the 10 underlying models. 40 bootstrap samples are obtained for each model (total: 400). Computation is parallelised over models.
2023-03-02 17:17:07	MESSAGE	    Computing data for decision curve analysis.
2023-03-02 17:17:07	MESSAGE	      Computing the bias-corrected estimate with confidence interval of the value(s) of interest for the ensemble model from the 10 underlying models. 40 bootstrap samples are obtained for each model (total: 400). Computation is parallelised over models.
2023-03-02 17:17:54	MESSAGE	    Assessing model calibration.
2023-03-02 17:17:54	MESSAGE	      Computing the bias-corrected estimate with confidence interval of the value(s) of interest for the ensemble model from the 10 underlying models. 40 bootstrap samples are obtained for each model (total: 400). Computation is parallelised over models.
2023-03-02 17:19:55	MESSAGE	    Computing receiver-operating characteristic curves.
2023-03-02 17:19:55	MESSAGE	      Computing the bias-corrected estimate with confidence interval of the value(s) of interest for the ensemble model from the 10 underlying models. 40 bootstrap samples are obtained for each model (total: 400). Computation is parallelised over models.
2023-03-02 17:21:16	MESSAGE	    Computing confusion matrix.
2023-03-02 17:21:16	MESSAGE	      Computing the point estimate of the value(s) of interest for the ensemble model as a whole. Computation is parallelised over bootstraps.
2023-03-02 17:21:18	MESSAGE	    Computing individual conditional expectation and partial dependence data for features in the dataset.
2023-03-02 17:21:18	MESSAGE	      Computing the point estimate of the value(s) of interest for the ensemble model as a whole. Computation is parallelised over bootstraps.
2023-03-02 17:21:19	MESSAGE	      Computing ICE / PD curves for "susp_tot".
2023-03-02 17:22:48	MESSAGE	  Evaluation: familiarData object 20230302154936_xgboost_tree_mrmr_1_1_pool_1_1_validation_data was created.
2023-03-02 17:22:48	MESSAGE	
Evaluation: Creating collection pooled_data
2023-03-02 17:22:54	MESSAGE	
Evaluation: Exporting data from collection pooled_data
