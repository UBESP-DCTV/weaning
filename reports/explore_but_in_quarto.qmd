---
title: "Explore but in quarto"
author: "AP"
format:
  html:
    embed-resources: true
    code-fold: true
    code-summary: "Show the code"
editor: visual
---

## Preliminary preprocessing

```{r}
library(tidyverse)
library(gtsummary)
library(targets)
library(yardstick)
# install.packages("familiar", dependencies = TRUE)
library(familiar)
#source("R/evaluation.R")

test_ids <- tar_read(idsTest)

baseline <- tar_read(pt_names) |>
  mutate( test_set = id_univoco %in% test_ids)
daily <- tar_read(pt_registry) |>
  mutate( test_set = id_univoco %in% test_ids) |>
  filter(sbt != -1)
trd <- tar_read(weaningsTRD) |>
  mutate( test_set = id_univoco %in% test_ids)
```

## Test set check

-   Baseline differences

-   Daily differences (all but study days)

-   Daily differences ( study days)

-   TRD differences

New version (density plot)

```{r}
tar_read(test_set_check)
```

## Dummy models

-   Model 0 always predict Class 0
-   Model 1 always predict Class 1
-   Model 2 always predict Class 2

```{r}
metric_table <- tibble()
observed <- daily |>
  filter(test_set == TRUE) |>
  select(sbt) |>
  unlist()

pred_obs <- tibble(
  observed,
  pred0 = rep_len(0, length.out = length(observed)),
  pred1 = rep_len(1, length.out = length(observed)),
  pred2 = rep_len(2, length.out = length(observed))
  ) |>
  dplyr::mutate(
    dplyr::across(
      dplyr::everything(),
      ~ factor(.x, levels = c(0,1,2))
  ))

#example
table(pred_obs$pred0, pred_obs$observed)

metric_table <- pred_obs |>
    multi_metric(
      truth = observed,
      estimate = pred0,
      estimator = "macro_weighted"
  ) |>
  rename("All 0" = ".estimate")

metric_table <- metric_table |>
  left_join(
      multi_metric(
        data = pred_obs,
        truth = observed,
        estimate = pred1,
        estimator = "macro_weighted"
      ) |> rename("All 1" = ".estimate"),
    by = NULL
  ) |>
  left_join(
      multi_metric(
        data = pred_obs,
        truth = observed,
        estimate = pred2,
        estimator = "macro_weighted"
      ) |> rename("All 2" = ".estimate"),
    by = NULL
  )
```

-   Model 3 predicts with random classes
-   Model 4 predicts random with observed class frequencies

```{r}
daily |>
  select(sbt, test_set) |>
  tbl_summary(
    by = test_set,
    label = sbt ~ "Daily attempt"
  ) |>
  add_p() |>
  add_q()

set.seed(4242)
pred_obs <- pred_obs |>
  mutate(
    pred3 = sample(0:2, size = length(observed), replace = TRUE),
    pred4 = sample(
      0:2,
      size = length(observed),
      replace = TRUE,
      prob = c(78,12,10)
    )
  ) |>
  dplyr::mutate(
    dplyr::across(
      dplyr::everything(),
      ~ factor(.x, levels = c(0,1,2))
  ))

metric_table <- metric_table |>
  left_join(
      multi_metric(
        data = pred_obs,
        truth = observed,
        estimate = pred3,
        estimator = "macro_weighted"
      ) |> rename("Coin toss" = ".estimate"),
    by = NULL
  ) |>
  left_join(
      multi_metric(
        data = pred_obs,
        truth = observed,
        estimate = pred4,
        estimator = "macro_weighted"
      ) |> rename("Stratified random" = ".estimate"),
    by = NULL
  )
```

Model 5 predicts with baseline and daily input

```{r}
dailydata <- daily |>
  select(id_univoco,
         starts_with("ega"),
         sofa,
         susp_tot,
         giorno_studio,
         sbt,
         test_set) |>
  left_join(
    y = baseline |>
      select(
        id_univoco,
        type,
        sesso,
        anni_eta,
        bmi,
        ibw,
        saps,
        reason
      ),
    by = "id_univoco"
  )
```

```{r, eval=FALSE}
model5 <- train_familiar(
  data = filter(dailydata, test_set == FALSE),
  experiment_dir = file.path(here::here(), "train_xgboost"),
  experimental_design = "cv(fs+mb,10,1)",
  sample_id_column = "id_univoco",
  outcome_type = "multinomial",
  outcome_column = "sbt",
  fs_method = "elastic_net",
  learner = "xgboost_tree",
  evaluation_metric = "balanced_accuracy",
  imputation_method = "simple"
  )

#Training time ~ 10h
saveRDS(model5, file = "./models/xgboost_v2.RDS")
```

After being trained, model can be retrieved from memory to obtain predicitons

```{r}
xgb_model <- readRDS("./models/xgboost_v2.RDS")

xgb_preds <- familiar::predict(
  xgb_model,
  filter(dailydata, test_set == TRUE),
  type = "default"
)

pred_obs <- pred_obs |> 
  bind_cols("xgb_preds" = xgb_preds[["predicted_class"]])

metric_table <- metric_table |>
  left_join(
      multi_metric(
        data = pred_obs,
        truth = observed,
        estimate = xgb_preds,
        estimator = "macro_weighted"
      ) |> rename("XG Boosted trees" = ".estimate"),
    by = NULL
  )
```

Metric display all at once

```{r}
metric_table
```

## Keras models TEST (do not use)

```{r, eval = FALSE}
library(keras)

# Load model
e19a78 <- load_model_hdf5("C:/R/weaning/models/models_epoch-19_acc_0.78.hdf5", custom_objects = NULL, compile = TRUE)

# Preparing test data
batch_size <- 32
ids_test <- tar_read(idsTest)
db_test_raw <- tar_read(dbTest)

#this is a temporary approximatrion, appropriate validation coefficients from selected model should be used
means_baseline <- get_means(db_test_raw, "baseline")
means_daily <- get_means(db_test_raw, "daily")
means_trd <- get_means(db_test_raw, "trd")
sd_baseline <- get_sd(db_test_raw, "baseline")
sd_daily <- get_sd(db_test_raw, "daily")
sd_trd <- get_sd(db_test_raw, "trd")

db_test <- db_test_raw |>
  normalize_baseline(means_baseline, sd_baseline) |>
  normalize_daily(means_daily, sd_daily) |>
  normalize_trd(means_trd, sd_trd)

test_generator <- create_batch_generator(db_test, batch_size)
test_n_batches <- db_test |>
  purrr::map_int(~ceiling(length(.x[["ids"]]) / batch_size)) |>
  sum()
rm(db_test, db_test_raw)

# Predict
preds <- predict(
  object = e19a78,
  x = test_generator,
  batch_size = batch_size,
  steps = test_n_batches
  )

obs <- tar_read(dbTest) |> 
  purrr::map("out") |> 
  unlist()#use.names = FALSE)
table(apply(preds, 1, which.max)-1, obs)
```

Obtain prediction from validation instead

```{r}
seed <- 1234
library(keras)
preds <- list()

# Load model
e19a78 <- load_model_hdf5("C:/R/weaning/models/models_epoch-19_acc_0.78.hdf5", custom_objects = NULL, compile = TRUE)

# Preparing test data
k_folds <- 5
batch_size <- 32
ids_trval <- tar_read(idsTrVal)
db_trval <- tar_read(dbTrVal)

set.seed(seed)
fold_id <- sample(rep(seq_len(k_folds), length.out = length(ids_trval)))

for (i in seq_len(k_folds)) {
  ids_in_val <- ids_trval[fold_id == i]
  ids_in_train <- ids_trval[fold_id != i]

  db_tr <- db_trval |> filter_db_ids(ids_in_train)
  
  #this is a temporary approximatrion, appropriate 
  #validation coefficients from selected model should be used

  means_baseline <- get_means(db_tr, "baseline")
  means_daily <- get_means(db_tr, "daily")
  means_trd <- get_means(db_tr, "trd")
  sd_baseline <- get_sd(db_tr, "baseline")
  sd_daily <- get_sd(db_tr, "daily")
  sd_trd <- get_sd(db_tr, "trd")
  ui_todo("Normalization coeff obtained")

  db_val <- db_trval |>
    filter_db_ids(ids_in_val) |>
    normalize_baseline(means_baseline, sd_baseline) |>
    normalize_daily(means_daily, sd_daily) |>
    normalize_trd(means_trd, sd_trd)
  val_generator <- create_batch_generator(db_val, batch_size)
  val_n_batches <- db_val |>
    purrr::map_int(~ceiling(length(.x[["ids"]]) / batch_size)) |>
    sum()

   preds[i] <- predict(
      object = e19a78,
      x = val_generator,
      batch_size = batch_size,
      steps = val_n_batches
    )
  ui_todo("Preds done")
}
```

## Plot a patient (and predictions)

Still gives "

    Can't recycle `..1` (size 1180) to match `predicted` (size 1477).

" error

```{r}
#pt_ids <- tar_read(idsTest)[12] # Use only if you want TEST
pt_ids <- tar_read(idsTrVal)[1:9]

#tar_read(dbTest) |> # Use only if you want TEST
tar_read(dbTrVal) |>
  purrr::map("out") |> 
  unlist() |>
  as_tibble(rownames = "patient") |>
  rename("observed" = "value") |>
  mutate(patient = stringr::str_sub(patient, -5)) |>
  group_by(patient) |>
  mutate(giorno_studio = row_number()) |>
  ungroup() |>
  bind_cols(
    predicted = apply(preds, 1, which.max) -1
    #predicted = sample(0:2, 1180, replace = TRUE)
  ) |>
  dplyr::filter(patient %in% pt_ids) |>
  dplyr::mutate(
    correct = observed == predicted,
    across(c(observed, predicted),
      ~ .x |> 
        as.character() |>
        forcats::fct_recode(
          "invasive MV" = "0",
          "invasive MV" = "2",
          "Successful MV Stop" = "1"
        ) |>
        forcats::fct_relevel(c("invasive MV",
                               "Successful MV Stop"))
      )
    ) |>
  ggplot(aes( x = giorno_studio)) +
  geom_step(
    aes( y = observed,
         group = "observed"),
    color = "grey70",
    direction = "mid") +
  geom_point(
    aes(y = observed),
    color = "grey70",
    size = 5) +
  geom_point(aes(
    y = predicted,
    color = predicted),
    size = 2) +
  facet_wrap(~patient, scales = "free_x") +
  scale_color_brewer(palette = "Dark2", direction=-1) +
  labs(
    title = "Predicted vs Observed clinical course",
    x = "Days of study",
    y = "",
    color = "AI Model suggestion"
  )
```

## 
