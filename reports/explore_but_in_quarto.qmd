---
title: "Explore but in quarto"
author: "AP"
format:
  html:
    embed-resources: true
    code-fold: true
    code-summary: "Show the code"
editor: visual
---

## Preliminary preprocessing

```{r}

library(keras)
library(tidyverse)
library(gtsummary)
library(targets)
library(yardstick)
# install.packages("familiar", dependencies = TRUE)
library(familiar)
list.files(here::here("R"), pattern = "\\.R", full.names = TRUE) |>
  lapply(source) |>
  invisible()

test_ids <- tar_read(idsTest)

baseline <- tar_read(pt_names) |>
  mutate( test_set = id_univoco %in% test_ids)
daily <- tar_read(pt_registry) |>
  mutate( test_set = id_univoco %in% test_ids) |>
  filter(sbt != -1)
trd <- tar_read(weaningsTRD) |>
  mutate( test_set = id_univoco %in% test_ids)

a <- trd |> filter(test_set) |> select(date, id_univoco)|> distinct() 
b <- daily |> filter(test_set) |> mutate(date = data_lettura) |> select(date, id_univoco)|> distinct() 

inner_join(a, b)
```

## Test set check

-   Baseline differences

-   Daily differences (all but study days)

-   Daily differences ( study days)

-   TRD differences

New version (density plot)

```{r}
tar_make(test_set_check)
```

## Dummy models

-   Model 0 always predict Class 0
-   Model 1 always predict Class 1
-   Model 2 always predict Class 2

```{r}
metric_table <- tibble()
observed <- daily |>
  filter(test_set == TRUE) |>
  select(sbt) |>
  unlist()
giorno_studio <- daily |>
  filter(test_set == TRUE) |>
  select(giorno_studio) |>
  unlist()
patient <- daily |>
  filter(test_set == TRUE) |>
  select(id_univoco) |>
  unlist()

pred_obs <- tibble(
  observed,
  giorno_studio,
  patient,
  pred0 = rep_len(0, length.out = length(observed)),
  pred1 = rep_len(1, length.out = length(observed)),
  pred2 = rep_len(2, length.out = length(observed))
  ) |>
  dplyr::mutate(
    dplyr::across(
      dplyr::everything(),
      ~ factor(.x, levels = c(0,1,2))
  ))

#example
table(pred_obs$pred0, pred_obs$observed)

metric_table <- pred_obs |>
    multi_metric(
      truth = observed,
      estimate = pred0,
      estimator = "macro_weighted"
  ) |>
  rename("All 0" = ".estimate")

metric_table <- metric_table |>
  left_join(
      multi_metric(
        data = pred_obs,
        truth = observed,
        estimate = pred1,
        estimator = "macro_weighted"
      ) |> rename("All 1" = ".estimate"),
    by = NULL
  ) |>
  left_join(
      multi_metric(
        data = pred_obs,
        truth = observed,
        estimate = pred2,
        estimator = "macro_weighted"
      ) |> rename("All 2" = ".estimate"),
    by = NULL
  )
```

-   Model 3 predicts with random classes
-   Model 4 predicts random with observed class frequencies

```{r}
daily |>
  select(sbt, test_set) |>
  tbl_summary(
    by = test_set,
    label = sbt ~ "Daily attempt"
  ) |>
  add_p() |>
  add_q()

set.seed(4242)
pred_obs <- pred_obs |>
  mutate(
    pred3 = sample(0:2, size = length(observed), replace = TRUE),
    pred4 = sample(
      0:2,
      size = length(observed),
      replace = TRUE,
      prob = c(78,12,10)
    )
  ) |>
  dplyr::mutate(
    dplyr::across(
      dplyr::everything(),
      ~ factor(.x, levels = c(0,1,2))
  ))

metric_table <- metric_table |>
  left_join(
      multi_metric(
        data = pred_obs,
        truth = observed,
        estimate = pred3,
        estimator = "macro_weighted"
      ) |> rename("Coin toss" = ".estimate"),
    by = NULL
  ) |>
  left_join(
      multi_metric(
        data = pred_obs,
        truth = observed,
        estimate = pred4,
        estimator = "macro_weighted"
      ) |> rename("Stratified random" = ".estimate"),
    by = NULL
  )
```

Model 5 predicts with baseline and daily input

```{r}
dailydata <- tar_read(dailydata)
```

```{r, eval=FALSE}
model5 <- train_familiar(
  data = filter(dailydata, test_set == FALSE),
  experiment_dir = file.path(here::here(), "train_xgboost"),
  experimental_design = "cv(fs+mb,10,1)",
  sample_id_column = "id_univoco",
  outcome_type = "multinomial",
  outcome_column = "sbt",
  fs_method = "elastic_net",
  learner = "xgboost_tree",
  evaluation_metric = "balanced_accuracy",
  imputation_method = "simple"
  )

#Training time ~ 8h
```

After being trained, model can be retrieved from memory to obtain predicitons

```{r}
xgb_model <- readRDS(here::here("train_xgboost/trained_models/xgboost_tree/elastic_net/20230312003958_xgboost_tree_elastic_net_1_1_ensemble.RDS"))

xgb_preds <- familiar::predict(
  xgb_model,
  dplyr::filter(dailydata, test_set == TRUE),
  type = "default"
)

pred_obs <- pred_obs |> 
  bind_cols("xgb_preds" = xgb_preds[["predicted_class"]])

metric_table <- metric_table |>
  left_join(
      multi_metric(
        data = pred_obs,
        truth = observed,
        estimate = xgb_preds,
        estimator = "macro_weighted"
      ) |> rename("XG Boosted trees" = ".estimate"),
    by = NULL
  )
```

Interesting plots on xgboost

```{r}
roc_plot <- familiar::plot_auc_roc_curve(object=xgb_model,
   data=filter(dailydata, test_set == TRUE))

cm_plot <- familiar::plot_confusion_matrix(object=xgb_model,
  data=filter(dailydata, test_set == TRUE))

vip_plot <- familiar::plot_model_signature_variable_importance(
  object=xgb_model,
  data=filter(dailydata, test_set == TRUE)
)

ice_plot_susp <- familiar::plot_ice(
  object=xgb_model,
  draw = TRUE,
  data=filter(dailydata, test_set == TRUE),
  features="susp_tot",
  anchor_values=list("susp_tot"= 12))

ice_plot_reason <- familiar::plot_ice(
  object=xgb_model,
  draw = TRUE,
  data=filter(dailydata, test_set == TRUE),
  features="reason")

library(familiar)
map(xgb_model, ~ plot_model_signature_variable_importance(
  object = .x,
  data = filter(dailydata, test_set == TRUE)))


#Plot trees
library(DiagrammeR)
xgb.plot.tree(model = xgb_model$`xgboost_tree/elastic_net/20230309110803_xgboost_tree_elastic_net_2_1_model.RDS`@model,
              trees = 1:10)
```

Metric display all at once

```{r}
metric_table |>
  gt::gt() |>
  gt::fmt_number(
    columns = 3:8,
    decimals = 2
  )
```

## Keras models TEST

```{r}
# Load model
e15a79 <- load_model_hdf5(here::here("models/models_epoch-15_acc_0.79.hdf5"), custom_objects = NULL, compile = TRUE)

# Preparing test data
batch_size <- 32
ids_test <- tar_read(idsTest)
db_test_raw <- tar_read(dbTest)
db_trval <- tar_read(dbTrVal)

#this is a temporary approximatrion, appropriate validation coefficients from selected model should be used
means_baseline <- get_means(db_trval, "baseline")
means_daily <- get_means(db_trval, "daily")
means_trd <- get_means(db_trval, "trd")
sd_baseline <- get_sd(db_trval, "baseline")
sd_daily <- get_sd(db_trval, "daily")
sd_trd <- get_sd(db_trval, "trd")

db_test <- db_test_raw |>
  normalize_baseline(means_baseline, sd_baseline) |>
  normalize_daily(means_daily, sd_daily) |>
  normalize_trd(means_trd, sd_trd)

test_generator <- create_batch_generator(db_test, batch_size)
test_n_batches <- db_test |>
  purrr::map_int(~ceiling(length(.x[["ids"]]) / batch_size)) |>
  sum()

# Predict
preds <- predict(
  object = e15a79,
  x = test_generator,
  batch_size = batch_size,
  steps = test_n_batches
  )

obs <- tar_read(dbTest) |> 
  purrr::map("out") |> 
  unlist()#use.names = FALSE)

t <- table(apply(preds, 1, which.max)-1, obs) #[c(1,3,2),c(1,3,2)]

sum(t*cost_matrix, na.rm = TRUE) / sum((!is.na(cost_matrix) & cost_matrix != 0 ) *t)
```

```{r}
pred_obs <- pred_obs |>
  mutate(pred_test = apply(preds, 1, which.max)-1, obs) |>
  dplyr::mutate(
    dplyr::across(
      dplyr::everything(),
      ~ factor(.x, levels = c(0,1,2))
  ))

metric_table <- metric_table |>
  left_join(
      multi_metric(
        data = pred_obs,
        truth = observed,
        estimate = pred_test,
        estimator = "macro_weighted"
      ) |> rename("AI model" = ".estimate"),
    by = NULL
  )
```

Obtain prediction from validation instead

```{r}
seed <- 1234
library(keras)
preds <- list()

# Load model
e19a78 <- load_model_hdf5("C:/R/weaning/models/models_epoch-19_acc_0.78.hdf5", custom_objects = NULL, compile = TRUE)

# Preparing test data
k_folds <- 5
batch_size <- 32
ids_trval <- tar_read(idsTrVal)
db_trval <- tar_read(dbTrVal)

set.seed(seed)
fold_id <- sample(rep(seq_len(k_folds), length.out = length(ids_trval)))

for (i in seq_len(k_folds)) {
  ids_in_val <- ids_trval[fold_id == i]
  ids_in_train <- ids_trval[fold_id != i]

  db_tr <- db_trval |> filter_db_ids(ids_in_train)
  
  #this is a temporary approximatrion, appropriate 
  #validation coefficients from selected model should be used

  means_baseline <- get_means(db_tr, "baseline")
  means_daily <- get_means(db_tr, "daily")
  means_trd <- get_means(db_tr, "trd")
  sd_baseline <- get_sd(db_tr, "baseline")
  sd_daily <- get_sd(db_tr, "daily")
  sd_trd <- get_sd(db_tr, "trd")
  ui_todo("Normalization coeff obtained")

  db_val <- db_trval |>
    filter_db_ids(ids_in_val) |>
    normalize_baseline(means_baseline, sd_baseline) |>
    normalize_daily(means_daily, sd_daily) |>
    normalize_trd(means_trd, sd_trd)
  val_generator <- create_batch_generator(db_val, batch_size)
  val_n_batches <- db_val |>
    purrr::map_int(~ceiling(length(.x[["ids"]]) / batch_size)) |>
    sum()

   preds[i] <- predict(
      object = e19a78,
      x = val_generator,
      batch_size = batch_size,
      steps = val_n_batches
    )
  ui_todo("Preds done")
}
```

## Plot a patient (and predictions)

Still gives "

    Can't recycle `..1` (size 1180) to match `predicted` (size 1477).

" error

```{r}
#pt_ids <- tar_read(idsTest)[12] # Use only if you want TEST
pt_ids <- tar_read(idsTest)

#tar_read(dbTest) |> # Use only if you want TEST
obs_pred <- tar_read(dbTest) |>
  purrr::map("out") |> 
  unlist() |>
  as_tibble(rownames = "patient") |>
  rename("observed" = "value") |>
  mutate(patient = stringr::str_sub(patient, -5)) |>
  group_by(patient) |>
  mutate(giorno_studio = row_number()) |>
  ungroup() |>
  bind_cols(
    predicted = apply(preds, 1, which.max) -1
    #predicted = sample(0:2, 1180, replace = TRUE)
  ) |>
  dplyr::filter(patient %in% pt_ids) 

pred_obs |>
  dplyr::mutate(
    #correct = observed == predicted,
    predicted = xgb_preds,
    suggested  = predicted,
    across(c(observed, predicted),
      ~ .x |> 
        as.character() |>
        forcats::fct_recode(
          # "invasive MV" = "0",
          # "invasive MV" = "2",
          # "Successful MV Stop" = "1"
          "SBT n.a" = "0",
          "SBT ok" = "1",
          "SBT fail" = "2"
        ) |>
        forcats::fct_relevel(
          #c("invasive MV", "Successful MV Stop")
          c("SBT n.a","SBT fail", "SBT ok")
        )
      ),
    across(c(suggested),
      ~ .x |> 
        as.character() |>
        forcats::fct_recode(
          "continue MV" = "0",
          "continue MV" = "2",
          "SBT" = "1"
        ) |>
        forcats::fct_relevel(
          c("continue MV", "SBT")
        )
      )
    ) |>
  ggplot(aes( x = giorno_studio)) +
  geom_step(
    aes( y = observed,
         group = "observed"),
    color = "grey70",
    direction = "mid") +
  geom_point(
    aes(y = observed),
    color = "grey70",
    size = 5) +
  geom_point(aes(
    y = predicted,
    color = suggested),
    size = 2) +
  facet_wrap(~patient, scales = "free_x") +
  scale_color_brewer(palette = "Dark2", direction=-1) +
  labs(
    title = "Predicted vs Observed clinical course",
    x = "Days of study",
    y = "",
    color = "AI Model suggestion"
  ) +
  theme(legend.position = "top")
```

## 
